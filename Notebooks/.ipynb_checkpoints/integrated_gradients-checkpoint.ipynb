{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basemodel_v3_copy import NaiveNet_v1, model_v3\n",
    "from util_layers import BahdanauAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = 553\n",
    "num_task = 8\n",
    "length = 101\n",
    "radius = length // 2\n",
    "model_path = './ModelLib/trained_model_51seqs.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_hdf('./Data/data_RM.h5','test_in').iloc[:,2000-radius*4:2004+radius*4].to_numpy()\n",
    "x = torch.cuda.FloatTensor(x)\n",
    "x = x.view(x.size(0),-1,4).transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.unsqueeze(x[data_index,...],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "input_y = pd.read_hdf('./Data/data_RM.h5','test_out').iloc[data_index,:]\n",
    "class_names = list(input_y.index)\n",
    "print(list(input_y[input_y==1].index))\n",
    "input_y = torch.cuda.FloatTensor(input_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_y[input_y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-39cc882f4a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaiveNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_task\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_task\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# model = nn.DataParallel(model_v3(num_task)).cuda()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\DeepRiMo\\basemodel_v3_copy.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_size, num_task)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0min_features_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0min_features_1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0min_features_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0min_features_2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         self.SharedFC = nn.Sequential(nn.Linear(in_features=128*in_features_3,out_features=1024),\n\u001b[0;32m     34\u001b[0m                                     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Flatten'"
     ]
    }
   ],
   "source": [
    "model = NaiveNet(input_size=length,num_task=num_task).cuda()\n",
    "# model = nn.DataParallel(model_v3(num_task)).cuda()\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outputs_and_gradients(inputs, model, cuda=False):\n",
    "    # do the pre-processing\n",
    "    predict_idx = None\n",
    "    gradients = []\n",
    "    n_steps = len(inputs)\n",
    "    for i in range(n_steps):\n",
    "        input = inputs[i]\n",
    "        input.requires_grad = True\n",
    "        input.retain_grad()\n",
    "        output = model(input)\n",
    "        \n",
    "        # clear grad\n",
    "        model.zero_grad()\n",
    "        output[2].backward(retain_graph=True)\n",
    "        gradient = input.grad.detach().cpu().numpy()[0]\n",
    "        gradients.append(gradient)\n",
    "    gradients = np.array(gradients)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrated gradients\n",
    "def integrated_gradients(inputs, model, predict_and_gradients, baseline, steps=50, cuda=False):\n",
    "    if baseline is None:\n",
    "        baseline = 0 * inputs \n",
    "    # scale inputs and compute gradients\n",
    "    scaled_inputs = [baseline + (float(i) / steps) * (inputs - baseline) for i in range(0, steps + 1)]\n",
    "    grads = predict_and_gradients(scaled_inputs, model, cuda)\n",
    "    avg_grads = np.average(grads[:-1], axis=0)\n",
    "    avg_grads = np.expand_dims(avg_grads, axis=0)\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    baseline = baseline.cpu().numpy()\n",
    "    integrated_grad = (inputs - baseline) * avg_grads\n",
    "    return integrated_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_baseline_integrated_gradients(inputs, model, predict_and_gradients, steps, num_random_trials, cuda):\n",
    "    all_intgrads = []\n",
    "    for i in range(num_random_trials):\n",
    "        integrated_grad = integrated_gradients(inputs, model, predict_and_gradients, \\\n",
    "                                                baseline=torch.cuda.FloatTensor(np.random.random(inputs.shape)), \\\n",
    "                                                steps=steps, cuda=cuda)\n",
    "        all_intgrads.append(integrated_grad)\n",
    "        print('the trial number is: {}'.format(i))\n",
    "    avg_intgrads = np.average(np.array(all_intgrads), axis=0)\n",
    "    return avg_intgrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the trial number is: 0\n",
      "the trial number is: 1\n",
      "the trial number is: 2\n",
      "the trial number is: 3\n",
      "the trial number is: 4\n",
      "the trial number is: 5\n",
      "the trial number is: 6\n",
      "the trial number is: 7\n",
      "the trial number is: 8\n",
      "the trial number is: 9\n"
     ]
    }
   ],
   "source": [
    "attributions = random_baseline_integrated_gradients(input_x, model, calculate_outputs_and_gradients, \\\n",
    "                                                        steps=50, num_random_trials=10, cuda=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients_ = pd.DataFrame(data=np.squeeze(attributions,0).T,columns=['A','C','G','T'])\n",
    "integrated_gradients_.to_csv('./Seqs/ig_onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
