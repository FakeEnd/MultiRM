{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Scripts/\")\n",
    "from models import model_v3\n",
    "from util_funs import seq2index, cutseqs, highest_x, index2word_, word2index_\n",
    "from util_att import evaluate, cal_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_index = 499\n",
    "length = 51  \n",
    "radius = length // 2\n",
    "num_task = 12\n",
    "data_index = 841 # 841,833,802\n",
    "my_dict = pickle.load(open('../Data/embeddings_12RM_new2.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_in', 'test_in_3_mers', 'test_in_nucleo', 'test_out', 'train_in', 'train_in_3_mers', 'train_in_nucleo', 'train_out', 'valid_in', 'valid_in_3_mers', 'valid_in_nucleo', 'valid_out']>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RM_data = h5py.File('../Data/data_12RM.h5','r')\n",
    "RM_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 640,  453,  894,  349, 1053, 1128,  928,  720,  736,  289,   19,\n",
       "             315,  518,  348,  362,   77,  273,  805, 1042,  426],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = pd.read_hdf('../Data/data_12RM.h5','test_in_3_mers')\n",
    "input_x = input_x.iloc[:,middle_index-radius+1:middle_index+radius-1+1].sample(n=20)\n",
    "input_x.applymap(lambda x: index2word_(my_dict)[x])\n",
    "input_x_index = input_x.index\n",
    "input_x_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = pd.read_hdf('../Data/data_12RM.h5','test_out').iloc[input_x_index,:]\n",
    "# y_true = y_true.iloc[np.where(y_true==1)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_x = input_x.iloc[np.where(y_true==1)[0],:] # only take positive samples into account\n",
    "input_x_index = input_x.index\n",
    "input_x_nucleo = pd.read_hdf('../Data/data_12RM.h5','test_in_nucleo')\n",
    "input_x_nucleo = input_x_nucleo.iloc[input_x_index,middle_index-radius+1:middle_index+radius+2]\n",
    "input_x_nucleo_unmutated = input_x_nucleo.copy()\n",
    "input_x_nucleo_mutated_withinatt = input_x_nucleo.copy()\n",
    "input_x_nucleo_mutated_outatt = input_x_nucleo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = torch.cuda.FloatTensor(input_x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_v3(num_task,use_embedding=True).cuda()\n",
    "model_path = '../Weights/MultiRM/trained_model_51seqs.pkl'\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights, y_preds = evaluate(model,input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = np.array([[y_pred.detach().cpu().numpy()[i] for y_pred in y_preds] for i in range(len(input_x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = cal_attention(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  3,  5,  6,  7,  8, 10, 11, 12, 13, 17, 18, 19], dtype=int64),\n",
       " array([ 6,  3, 11,  9,  7,  7,  0,  3,  5,  3,  8, 10,  4], dtype=int64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_true==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3386944 , 0.02248525, 0.03054834, 0.09994186, 0.60452926,\n",
       "       0.7461709 , 0.01283268, 0.24701245, 0.52550745, 0.20857105,\n",
       "       0.04953952, 0.18871167, 0.1628074 ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = y_probs[np.where(y_true==1)]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = dict()\n",
    "for sample_idx,class_idx in zip(np.arange(0,len(y_probs)),np.where(y_true==1)[1]):\n",
    "    #dict_idx = y_true.index[sample_idx]\n",
    "    tmp = highest_x(attention[sample_idx, class_idx, :],w=5)\n",
    "    position_dict[sample_idx] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_withinattention_single(seq,exclude):\n",
    "\n",
    "    exclude1, exclude2 = exclude\n",
    "    \n",
    "    # choose mutation window\n",
    "    choose_exclude = np.random.uniform(0,1)\n",
    "    if choose_exclude <= 0.5:\n",
    "        start, end = exclude1\n",
    "    else:\n",
    "        start, end = exclude2\n",
    "    window_size = end - start + 1\n",
    "    \n",
    "    # choose mutation point\n",
    "    choose_point = np.random.uniform(0,1)\n",
    "    for i in range(1, window_size+1):\n",
    "        if choose_point <= i / window_size:\n",
    "            mutated_point = start+i-1\n",
    "            break\n",
    "    original_type = seq[mutated_point]\n",
    "    \n",
    "    \n",
    "    # choose mutation type\n",
    "    types = ['A','C','G','T']\n",
    "    left_types = types.remove(original_type)\n",
    "\n",
    "    choose_type = np.random.uniform(0,1)\n",
    "    \n",
    "    if choose_type <= 1 / 3:\n",
    "        mutate_type = types[0]\n",
    "    elif choose_type <= 2 / 3:\n",
    "        mutate_type = types[1]\n",
    "    else:\n",
    "        mutate_type = types[2]\n",
    "#     print(mutate_type)\n",
    "#     print(seq[mutated_point])\n",
    "#     print(mutated_point)\n",
    "    seq[mutated_point] = mutate_type\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23, 27), (7, 11))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = position_dict[0][1][1:], position_dict[0][2][1:]\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(exclude, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_outatt_single(seq, exclude):\n",
    "\n",
    "    exclude_low = exclude[np.argmin(exclude,axis=0)[0]]\n",
    "    exclude_high = exclude[np.argmax(exclude,axis=0)[0]]\n",
    "    \n",
    "    # choose mutation window\n",
    "    choose_exclude = np.random.uniform(0,1)\n",
    "    if choose_exclude <= 1 / 3:\n",
    "        start, end = 0, exclude_low[0]-1\n",
    "    elif choose_exclude <= 2 / 3:\n",
    "        start, end = exclude_low[1]+1, exclude_high[0]-1\n",
    "    else:\n",
    "        start, end = exclude_high[1]+1, len(seq)\n",
    "    window_size = end - start + 1\n",
    "    \n",
    "        # choose mutation point\n",
    "    choose_point = np.random.uniform(0,1)\n",
    "    for i in range(1, window_size+1):\n",
    "        if choose_point <= i / window_size:\n",
    "            mutated_point = start+i-1\n",
    "            break\n",
    "    original_type = seq[mutated_point]\n",
    "    \n",
    "    \n",
    "    # choose mutation type\n",
    "    types = ['A','C','G','T']\n",
    "    left_types = types.remove(original_type)\n",
    "\n",
    "    choose_type = np.random.uniform(0,1)\n",
    "    \n",
    "    if choose_type <= 1 / 3:\n",
    "        mutate_type = types[0]\n",
    "    elif choose_type <= 2 / 3:\n",
    "        mutate_type = types[1]\n",
    "    else:\n",
    "        mutate_type = types[2]\n",
    "#     print(mutate_type)\n",
    "#     print(seq[mutated_point])\n",
    "#     print(mutated_point)\n",
    "    seq[mutated_point] = mutate_type\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in position_dict.items(): \n",
    "    exclude = (value[1][1:], value[2][1:]) # take the top 2 windows\n",
    "    mutate_withinattention_single(input_x_nucleo_mutated_withinatt.iloc[key],exclude)\n",
    "    mutate_outatt_single(input_x_nucleo_mutated_outatt.iloc[key], exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_nucleo_mutated_withinatt.apply(lambda x: ''.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_mutated_withinatt_index = input_x_nucleo_mutated_withinatt.apply(lambda x: ''.join(x), axis=1).apply(lambda x: seq2index([x],my_dict))\n",
    "#input_x_mutated_withinatt_index.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_mutated_outatt_index = input_x_nucleo_mutated_outatt.apply(lambda x: ''.join(x), axis=1).apply(lambda x: seq2index([x],my_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_mutated_withinatt_index = np.vstack(input_x_mutated_withinatt_index.apply(lambda x: np.concatenate(x)).values)\n",
    "input_x_mutated_withinatt_index = torch.cuda.FloatTensor(input_x_mutated_withinatt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_mutated_outatt_index = np.vstack(input_x_mutated_outatt_index.apply(lambda x: np.concatenate(x)).values)\n",
    "input_x_mutated_outatt_index = torch.cuda.FloatTensor(input_x_mutated_outatt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_nucleo_mutated_withinatt.apply(lambda x: ''.join(x), axis=1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_nucleo.apply(lambda x: ''.join(x), axis=1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  8., 55., 16.,  7.,  7.,  7.,  7.,\n",
       "         7.,  7.,  7., 36., 37.,  2.,  3.,  0.,  1.,  2.,  3., 49., 19.,  9.,\n",
       "        22., 34., 10., 35., 33.,  9., 10., 35., 29., 48., 12., 11.,  3.,  4.,\n",
       "         4.,  4., 49., 51., 52.,  4.,  4.], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x_mutated_outatt_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  8., 55., 16.,  7.,  7.,  7.,  7.,\n",
       "         7.,  7.,  7., 36., 37.,  2.,  3.,  0.,  1., 61., 40., 46., 19.,  9.,\n",
       "        22., 34., 10., 35., 33.,  9., 10., 35., 29., 48., 12., 11.,  3.,  4.,\n",
       "         4.,  4.,  0., 11.,  3.,  4.,  4.], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x_mutated_withinatt_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  7.,  7.,  7.,  7.,  7.,  7.,  8., 55., 16.,  7.,  7.,  7.,  7.,\n",
       "         7.,  7.,  7., 36., 37.,  2.,  3.,  0.,  1.,  2.,  3., 49., 19.,  9.,\n",
       "        22., 34., 10., 35., 33.,  9., 10., 35., 29., 48., 12., 11.,  3.,  4.,\n",
       "         4.,  4.,  0., 11.,  3.,  4.,  4.], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights_withatt, y_preds_withatt = evaluate(model,input_x_mutated_withinatt_index)\n",
    "y_probs_withatt = np.array([[y_pred.detach().cpu().numpy()[i] for y_pred in y_preds_withatt] for i in range(len(input_x))])\n",
    "y_probs_withatt = y_probs_withatt[np.where(y_true==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights_outatt, y_preds_outatt = evaluate(model,input_x_mutated_outatt_index)\n",
    "y_probs_outatt = np.array([[y_pred.detach().cpu().numpy()[i] for y_pred in y_preds_outatt] for i in range(len(input_x))])\n",
    "y_probs_outatt = y_probs_outatt[np.where(y_true==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.0036258e-08, 1.6158506e-09, 2.9666955e-02, 2.1621055e-10,\n",
       "       5.7385948e-13, 4.6260449e-01, 1.2785241e-02, 2.4592088e-01,\n",
       "       1.3272518e-01, 2.0876878e-01, 4.9539518e-02, 1.8871167e-01,\n",
       "       1.6280740e-01], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_withatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33981052, 0.02020462, 0.02830241, 0.23942278, 0.6408705 ,\n",
       "       0.80353856, 0.01311817, 0.2532159 , 0.538238  , 0.2083857 ,\n",
       "       0.04953952, 0.18871167, 0.1628074 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_outatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3386944 , 0.02248525, 0.03054834, 0.09994186, 0.60452926,\n",
       "       0.7461709 , 0.01283268, 0.24701245, 0.52550745, 0.20857105,\n",
       "       0.04953952, 0.18871167, 0.1628074 ], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037802823"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(y_probs_withatt - y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001501281"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(y_probs_outatt - y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x_mutated_withinatt_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2word = index2word_(my_dict)\n",
    "index2word[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.remove('A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose(torch.from_numpy(seq2index(['ACCCA'],my_dict)),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(seq2index(['ACCCA'],my_dict)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
